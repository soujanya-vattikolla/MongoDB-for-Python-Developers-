{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter 3: Admin Backend.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM1dq+3Gcfnb53kYWcnSx90",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soujanya-vattikolla/MongoDB-for-Python-Developers-/blob/main/Chapter3%20AdminBackend.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read Concerns**\n",
        "\n",
        "* The default read concern in MongoDB is \"local\".\n",
        "  * This does not check that data has been replicated.\n",
        "* The read concern majority allows for more durable reads\n",
        "  * This only returns the data that has been replicated to a majority of nodes."
      ],
      "metadata": {
        "id": "mi3xU-2J6x6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Read Concerns**<br>\n",
        "**Problem:**<br>\n",
        "\n",
        "Which of the following Read Concerns are valid in a 3-node replica set?<br>\n",
        "\n",
        "* \"local\"\n",
        "\n",
        "    * This will return latest data from the node your application is connected to. This is the default read concern in MongoDB.\n",
        "\n",
        "* \"majority\"\n",
        "\n",
        "    * This will return data that has been committed to a majority of nodes in the replica set. In a 3-node set, 2 nodes constitute a majority."
      ],
      "metadata": {
        "id": "Hg9kGY1K8CFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ticket: User Report**<br>\n",
        "Problem:<br>\n",
        "\n",
        "User Story<br>\n",
        "\n",
        "\"As an administrator, I want to be able to view the top 20 users by their number of comments.\"<br>\n",
        "\n",
        "Task<br>\n",
        "\n",
        "For this ticket, you'll be required to modify one method in db.py, most_active_commenters. This method produces a report of the 20 most frequent commenters on the MFlix site."
      ],
      "metadata": {
        "id": "vDqMgVbO87D0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def most_active_commenters():\n",
        "    group = {\n",
        "        \"$group\":{\n",
        "            \"_id\": \"$email\",\n",
        "            \"count\": {\"$sum\": 1}\n",
        "        }\n",
        "    }\n",
        "    sort = { \"$sort\": {\"count\": -1} }\n",
        "    limit = { \"$limit\": 20}\n",
        "    pipeline = [group, sort, limit]\n",
        "\n",
        "    # we used Read Concern \"majority\" to make sure the data we read has been\n",
        "    # majority-committed\n",
        "    rc = ReadConcern(\"majority\")\n",
        "    comments = db.comments.with_options(read_concern=rc)\n",
        "    result = comments.aggregate(pipeline)\n",
        "    return list(result)"
      ],
      "metadata": {
        "id": "848TX9Gz-Daq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bulk Writes**"
      ],
      "metadata": {
        "id": "TuyeGDsL-arZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ordered Bulk Write**<br>\n",
        "* The default setting for bulk writes in MongoDB\n",
        "* Executes writes sequentially\n",
        "    * Will end execution after first write failure"
      ],
      "metadata": {
        "id": "mNKfEyjF-b4A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unordered Bulk Write**<br>\n",
        "  * Has to be specified with the flag:{ordered:false}\n",
        "  * Executes writes in parallel"
      ],
      "metadata": {
        "id": "rj_wYV-w_fWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Bulk writes allow database clients to send multiple writes.\n",
        "* Can either be ordered or unordered"
      ],
      "metadata": {
        "id": "vV5m1kS2_-73"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem:<br>\n",
        "\n",
        "Which of the following is true about bulk writes?<br>\n",
        "\n",
        "* Bulk writes decrease the effect of latency on overall operation time.\n",
        "\n",
        "    * By sending multiple documents in the same round trip, bulk writes reduce the effect of latency on the execution of an entire batch.\n",
        "\n",
        "* By default, bulk writes are ordered.\n",
        "\n",
        "    * This is the default behavior, but you can change this by passing the flag { ordered: false }."
      ],
      "metadata": {
        "id": "v-jZu82qAQf8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ticket: Migration**<br>\n",
        "Problem:<br>\n",
        "\n",
        "Task<br>\n",
        "\n",
        "For this ticket, you'll be required to complete the command-line script located in the migrations directory of mflix called movie_last_updated_migration.py.<br>\n",
        "\n",
        "Things always change, and a requirement has come down that the lastupdated value in each document of the movies collection needs to be stored as an ISODate rather than a String."
      ],
      "metadata": {
        "id": "7I62FljbBnAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient, UpdateOne\n",
        "from pymongo.errors import InvalidOperation\n",
        "from bson import ObjectId\n",
        "import dateutil.parser as parser\n",
        "\n",
        "host = \"mongodb://localhost:27017\"\n",
        "mflix = MongoClient(host)[\"sample_mflix\"]\n",
        "\n",
        "# here we're making sure \"lastupdated\" exists in the document as a string\n",
        "predicate = {\"lastupdated\": {\"$exists\": True, \"$type\": \"string\"}}\n",
        "# this projection only sends the \"lastupdated\" and \"_id\" fields back to the client\n",
        "projection = {\"lastupdated\": 1}\n",
        "\n",
        "cursor = mflix.movies.find(predicate, projection)\n",
        "\n",
        "updates = []\n",
        "for doc in cursor:\n",
        "    doc_id = doc.get('_id')\n",
        "    lastupdated = doc.get('lastupdated', None)\n",
        "    updates.append(\n",
        "        {\n",
        "            \"doc_id\": ObjectId(doc_id),\n",
        "            \"lastupdated\": parser.parse(lastupdated)\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(f\"{len(updates)} documents to update\")\n",
        "\n",
        "try:\n",
        "    # this will gather UpdateOne operations into a bulk_updates array\n",
        "    # we target the document with \"_id\" and then set its \"lastupdated\" field\n",
        "    # to the new ISODate type\n",
        "    bulk_updates = [UpdateOne(\n",
        "        {\"_id\": update.get(\"doc_id\")},\n",
        "        {\"$set\": {\"lastupdated\": update.get(\"lastupdated\")}}\n",
        "    ) for update in updates]\n",
        "\n",
        "    bulk_results = mflix.movies.bulk_write(bulk_updates)\n",
        "    print(f\"{bulk_results.modified_count} documents updated\")\n",
        "\n",
        "except InvalidOperation:\n",
        "    print(\"no updates necessary\")\n",
        "except Exception as e:\n",
        "    print(str(e))"
      ],
      "metadata": {
        "id": "UFz8DOkSF-5T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}