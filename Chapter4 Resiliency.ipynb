{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter 4: Resiliency.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMeAOpQK5xSlCmBxk8DY+up",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soujanya-vattikolla/MongoDB-for-Python-Developers-/blob/main/Chapter4%20Resiliency.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Connection Pooling**"
      ],
      "metadata": {
        "id": "_XoJ2G6ywLwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Connection pools allow for reuse of connections.\n",
        "* Subsequent requests appear faster to the client.\n",
        "* Default size of 100."
      ],
      "metadata": {
        "id": "TShHiJTa4eA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem:**<br>\n",
        "\n",
        "Which of the following are benefits of connection pooling?<br>\n",
        "\n",
        "* New operations can be serviced with pre-existing connections, so a new connection doesn't have to be created each time.\n",
        "\n",
        "  * This is the main benefit from using a connection pool. The overhead of creating a TCP connection often results in waiting time, but this waiting time can be avoided by reusing a connection.\n",
        "\n",
        "* A large influx of operations can be handled more quickly with a pool of existing connections.\n",
        "\n",
        "    * A common cause of application crashes is the inability of that application to deal with an influx of operations to perform. By creating a lot of available connections before they are needed, the application has the bandwidth to service as many requests as connections, without having to create any new connections."
      ],
      "metadata": {
        "id": "OzVFiTm05V68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ticket: Connection Pooling**<br>\n",
        "Problem:<br>\n",
        "\n",
        "Task<br>\n",
        "\n",
        "For this ticket, you'll be required to modify the configuration of MongoClient to set the maximum size of the connection pool to 50 connections.<br>\n",
        "\n",
        "The MongoClient in db.py is initialized in the get_db method."
      ],
      "metadata": {
        "id": "2_3shdD66DSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_db():\n",
        "    db = getattr(g, \"_database\", None)\n",
        "    MFLIX_DB_URI = current_app.config[\"MFLIX_DB_URI\"]\n",
        "    if db is None:\n",
        "        db = g._database = MongoClient(\n",
        "            MFLIX_DB_URI,\n",
        "            # here's where we set the maximum connection pool size to 50 connections\n",
        "            maxPoolSize=50\n",
        "        )[\"sample_mflix\"]\n",
        "    return db"
      ],
      "metadata": {
        "id": "GaWhV7tE7JiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Robust Client Configuration**"
      ],
      "metadata": {
        "id": "mi5N8SlK7U1_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Always use connection pooling.\n",
        "* Always specify a wtimeout with majority writes.\n",
        "* Always handle serverSelectionTimeout errors."
      ],
      "metadata": {
        "id": "RwjMNmEh7V5o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem:**<br>\n",
        "\n",
        "When should you set a wtimeout?<br>\n",
        "\n",
        "When our application is using a Write Concern more durable than w: 1.<br>\n",
        "\n",
        "The primary reason to use a wtimeout is because by default, when using Write Concern more durable than w: 1, there is no wtimeout, so the server will wait indefinitely for operations to complete.<br>\n",
        "\n",
        "Our application can use wtimeout to put a time limit on how long the server waits before a Write Concern is satisfied."
      ],
      "metadata": {
        "id": "msU8X-cZ9Gug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ticket: Timeouts**<br>\n",
        "Problem:<br>\n",
        "\n",
        "Task<br>\n",
        "\n",
        "For this ticket, you'll be required to modify the connection information for MongoClient to set a write timeout of 2500 milliseconds.<br>\n",
        "\n",
        "The MongoClient in db.py is initialized in the get_db method. "
      ],
      "metadata": {
        "id": "ff_F58-b9Rid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_db():\n",
        "    \"\"\"\n",
        "    Configuration method to return db instance\n",
        "    \"\"\"\n",
        "    db = getattr(g, \"_database\", None)\n",
        "    MFLIX_DB_URI = current_app.config[\"MFLIX_DB_URI\"]\n",
        "    if db is None:\n",
        "        db = g._database = MongoClient(\n",
        "            MFLIX_DB_URI,\n",
        "            maxPoolSize=50,\n",
        "\n",
        "            # here's where we set the wtimeout value to 2500 milliseconds\n",
        "            wtimeout=2500\n",
        "            \n",
        "        )[\"sample_mflix\"]\n",
        "    return db"
      ],
      "metadata": {
        "id": "mOqy88FC9npR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Writes with Error Handling**\n"
      ],
      "metadata": {
        "id": "WOQeYbQT9r0d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* DuplicateKeyError can occur on _id as well as fields in unique indexes."
      ],
      "metadata": {
        "id": "vmcuQ9Xr9r61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ticket: Handling Errors**<br>\n",
        "**Problem:**<br>\n",
        "\n",
        "Task<br>\n",
        "\n",
        "For this ticket, you'll be required to make the API more robust by handling exceptions. Specifically, what would happen should an incorrectly formatted _id be passed to get_movie in db.py?"
      ],
      "metadata": {
        "id": "S1lM7yUl_QqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_movie(id):\n",
        "    try:\n",
        "        pipeline = [\n",
        "            {\n",
        "                \"$match\": {\n",
        "                    \"_id\": ObjectId(id)\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"$lookup\": {\n",
        "                    \"from\": \"comments\",\n",
        "                    \"localField\": \"_id\",\n",
        "                    \"foreignField\": \"movie_id\",\n",
        "                    \"as\": \"comments\"\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "        movie = db.movies.aggregate(pipeline).next()\n",
        "        movie[\"comments\"] = sorted(\n",
        "            movie.get(\"comments\", []),\n",
        "            key=lambda c: c.get(\"date\"),\n",
        "            reverse=True\n",
        "        )\n",
        "        return movie\n",
        "    # this will handle \"InvalidId\" the same way as \"StopIteration\"\n",
        "    except (InvalidId, StopIteration) as _:\n",
        "        return None"
      ],
      "metadata": {
        "id": "L2Pf7-j-B4WV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ticket: Principle of Least Privilege**<br>\n",
        "Problem:<br>\n",
        "\n",
        "Task<br>\n",
        "\n",
        "For this ticket, you'll be required to add a new user on your Atlas cluster for the MFlix application to connect with.<br>\n",
        "\n",
        "The user should follow credentials:<br>\n",
        "\n",
        "username: mflixAppUser<br>\n",
        "password: mflixAppPwd<br>\n",
        "\n",
        "This user should have the readWrite role on the sample_mflix database. Use Add Default Privileges to assign the user this specific role.<br>\n",
        "\n",
        "After you have created this user, modify the SRV connection string in your configuration file so the application connects with the new username and password."
      ],
      "metadata": {
        "id": "Er6mfs7rIswf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "To complete this ticket, you had to create a user that only has readWrite access to the mflix database only.\n",
        "Then replace the authentication credentials, with this new user ones, in the MongoDB URI SRV string in your configuration file."
      ],
      "metadata": {
        "id": "g9PuMm5nIy1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Change Streams**"
      ],
      "metadata": {
        "id": "WbJjRRKhJVVi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Change streams can be opened against a collection.\n",
        "* Tracks data changes in real time.\n",
        "* Aggregation pipelines can be used to transform change event documents."
      ],
      "metadata": {
        "id": "81c7AzI3JWiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem:**<br>\n",
        "\n",
        "What of the following is true about Change Streams in Pymongo?<br>\n",
        "\n",
        "* They can be used to log changes to a MongoDB collection.\n",
        "\n",
        "    * As of MongoDB 4.0, Change Streams can also be used to log changes at a database, and even a cluster level.\n",
        "\n",
        "*  They output cursors, which contain change event documents.\n",
        "\n",
        "    * We can iterate through these cursors like any other Python iterable.\n",
        "\n",
        "* They accept pipelines, which can be used to filter output from the change stream.\n",
        "\n",
        "    * These pipelines accept a subset of the stages in an Aggregation query, such as $match, $project, and $addFields."
      ],
      "metadata": {
        "id": "AWwUt9LVLdBv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HlhQo11zL8a8"
      }
    }
  ]
}